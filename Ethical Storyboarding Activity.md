# Ethical Storyboarding Activity
##### Write a one-paragraph story describing a fictional person who was **positively** affected by a model trained with these data. #####

Juan, an uber eats driver, is constantly traveling from house to house, building to building, store to store. He loves how the navigation system is so accurate because it leads him to the exact location to where he has to pick up food and where to drop off the food. It even got to the point where if someone ordering food doesn’t have to give special directions on where Juan has to drop the food off at. All they have to do is pin the location and the GPS will take care of the rest and give a very precise location of where to meet the person to drop off the food.

##### Write a one-paragraph story describing a fictional person who was **negatively** affected by a model trained with these data. #####

Jason is a person who hates to leave the house when he doesn’t have to. He constantly orders food to be delivered to his house, but gets upset every time because the delivery drivers always pass his house. Jason is constantly upset because this happens so often, and he wonders what goes on with these delivery drivers that they always pass the house.

##### Describe at least **two sources of bias** the particular model in your story could have. #####

The first source of bias we could have is reporting bias. The issue we are trying to fix here is the mismatch of true location and displayed location on android smartphones. This type of bias could be present because the location data on the phone isn’t accurately reflected in the real world frequency.  Another type of bias could be based on the location of the devices being more or less accurate based on the geographic location.

##### Describe at least one way we could **modify the model** to mitigate this bias. #####
*E.g. What can we do when designing our model to account for inherent bias in the input data?*

One way we could modify the model to mitigate this bias would be to announce that instead of giving the exact location, we should say that it's near the location so that it helps the people not to be confused on where the GPS is taking them.

##### Describe at least one way we could **modify the dataset** to mitigate this bias. #####
*E.g. What could we do differently if we collected this data again?*

Make a column for distance when it's near a location. Maybe include some more data from other cities to make sure the results show the same patterns
##### Describe at least one way we could **modify the context** surrounding the model to mitigate this bias. #####
*E.g. What human practices or policies could we put in place to protect people within the social system where this model is used?* 

In terms of modifying the context we may have been able to alter more of the factors of the linear regression model to produce more accurate results or possibly combine parts of the other types of models in order to create a sort of compounded model
